{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.afd.de/demokratie-in-deutschland/\n",
      "Scraping: https://www.afd.de/aussenpolitik_sicherheit/\n",
      "Scraping: https://www.afd.de/euro-finanzen-eu/\n",
      "Scraping: https://www.afd.de/innere-sicherheit/\n",
      "Scraping: https://www.afd.de/zuwanderung-asyl/\n",
      "Scraping: https://www.afd.de/familie-bevoelkerung/\n",
      "Scraping: https://www.afd.de/bildung-schule/\n",
      "Scraping: https://www.afd.de/kultur-medien/\n",
      "Scraping: https://www.afd.de/sozialpolitik/\n",
      "Scraping: https://www.afd.de/steuern-finanzen-wirtschaft-arbeit/\n",
      "Scraping: https://www.afd.de/gesundheit/\n",
      "Scraping: https://www.afd.de/energie-umwelt-klima/\n",
      "Scraping: https://www.afd.de/umwelt-agrar-verbraucher/\n",
      "Scraping: https://www.afd.de/verkehr-infrastruktur/\n",
      "\n",
      "Gesamtanzahl der Wörter: 19620\n",
      "Daten erfolgreich in 'afd_lang.txt' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Liste der URLs zum Scrapen\n",
    "urls = [\n",
    "    \"https://www.afd.de/demokratie-in-deutschland/\",\n",
    "    \"https://www.afd.de/aussenpolitik_sicherheit/\",\n",
    "    \"https://www.afd.de/euro-finanzen-eu/\",\n",
    "    \"https://www.afd.de/innere-sicherheit/\",\n",
    "    \"https://www.afd.de/zuwanderung-asyl/\",\n",
    "    \"https://www.afd.de/familie-bevoelkerung/\",\n",
    "    \"https://www.afd.de/bildung-schule/\",\n",
    "    \"https://www.afd.de/kultur-medien/\",\n",
    "    \"https://www.afd.de/sozialpolitik/\",\n",
    "    \"https://www.afd.de/steuern-finanzen-wirtschaft-arbeit/\",\n",
    "    \"https://www.afd.de/gesundheit/\",\n",
    "    \"https://www.afd.de/energie-umwelt-klima/\",\n",
    "    \"https://www.afd.de/umwelt-agrar-verbraucher/\",\n",
    "    \"https://www.afd.de/verkehr-infrastruktur/\"\n",
    "]\n",
    "\n",
    "# Liste zum Speichern der extrahierten Inhalte\n",
    "content_list = []\n",
    "\n",
    "# User-Agent-Header, um Blockierungen zu vermeiden\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"Scraping: {url}\")  # Fortschrittsanzeige\n",
    "\n",
    "    # HTTP-Request senden\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # HTML-Inhalt parsen\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Alle Überschriften (fusion-toggle-heading)\n",
    "        for heading in soup.find_all(class_=\"fusion-toggle-heading\"):\n",
    "            heading_text = heading.get_text(separator=' ', strip=True)\n",
    "            content_list.append(f\"## {heading_text}\")\n",
    "\n",
    "            # Finde alle <p>-Tags innerhalb der Klasse \"panel-body toggle-content fusion-clearfix\"\n",
    "            paragraph_texts = []  # Liste für alle Texte der <p>-Tags\n",
    "\n",
    "            for paragraph in heading.find_all_next(class_=\"panel-body toggle-content fusion-clearfix\"):\n",
    "                # Alle <p>-Tags innerhalb dieser Klasse extrahieren und zu einem Fließtext zusammenfügen\n",
    "                for p in paragraph.find_all('p'):\n",
    "                    # Extrahiere den Text des <p>-Tags und entferne führende/folgende Leerzeichen\n",
    "                    paragraph_text = p.get_text(\" \", strip=True)\n",
    "                    if paragraph_text:\n",
    "                        paragraph_texts.append(paragraph_text)\n",
    "\n",
    "            # Verbinde alle Texte der <p>-Tags zu einem einzigen Fließtext und füge # am Anfang hinzu\n",
    "            if paragraph_texts:\n",
    "                content_list.append(f\"# {' '.join(paragraph_texts)}\")  # Zusammenführen ohne Leerzeilen und mit # am Anfang\n",
    "\n",
    "    else:\n",
    "        print(f\"Fehler beim Abrufen der Seite {url} - Status Code: {response.status_code}\")\n",
    "\n",
    "# Entferne leere Einträge\n",
    "content_list = [entry.strip() for entry in content_list if entry.strip()]\n",
    "\n",
    "# Die extrahierten Inhalte speichern\n",
    "afd_gesamt = \"\\n\".join(content_list)  # Doppelte Leerzeile für bessere Lesbarkeit\n",
    "with open(\"afd_lang.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(afd_gesamt)\n",
    "\n",
    "# Gesamtwortanzahl berechnen\n",
    "word_count = len(afd_gesamt.split())\n",
    "print(f\"\\nGesamtanzahl der Wörter: {word_count}\")\n",
    "print(\"Daten erfolgreich in 'afd_lang.txt' gespeichert.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
