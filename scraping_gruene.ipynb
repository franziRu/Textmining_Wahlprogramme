{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/klimagerechte-und-soziale-verkehrspolitik\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/die-wirtschaft-stärken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/klima-schützen\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/umwelt-und-natur-schützen\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/energiewende-vorantreiben\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/digitalisierung-vorantreiben\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/ländliche-räume-stärken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/faire-landwirtschaft\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/gesundheit-und-pflege-stärken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/eine-gerechte-gesellschaft\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/einwanderung-gestalten\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/eine-vielfältige-gesellschaft-gestalten\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/gleichberechtigung-verwirklichen\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/wertegeleitete-außenpolitik\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/demokratie-schuetzen-innere-sicherheit-staerken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/kultur-foerdern\n",
      "\n",
      "Gesamtanzahl der Wörter: 22360\n",
      "\n",
      "Datei erfolgreich gespeichert als 'gruene.txt'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URLs des Wahlprogramms der Grünen (auf mehrere Seiten verteilt)\n",
    "urls = [\n",
    "    \"https://www.gruene.de/themen/klimagerechte-und-soziale-verkehrspolitik\",\n",
    "    \"https://www.gruene.de/themen/die-wirtschaft-stärken\",\n",
    "    \"https://www.gruene.de/themen/klima-schützen\",\n",
    "    \"https://www.gruene.de/themen/umwelt-und-natur-schützen\",\n",
    "    \"https://www.gruene.de/themen/energiewende-vorantreiben\",\n",
    "    \"https://www.gruene.de/themen/digitalisierung-vorantreiben\",\n",
    "    \"https://www.gruene.de/themen/ländliche-räume-stärken\",\n",
    "    \"https://www.gruene.de/themen/faire-landwirtschaft\",\n",
    "    \"https://www.gruene.de/themen/gesundheit-und-pflege-stärken\",\n",
    "    \"https://www.gruene.de/themen/eine-gerechte-gesellschaft\",\n",
    "    \"https://www.gruene.de/themen/einwanderung-gestalten\",\n",
    "    \"https://www.gruene.de/themen/eine-vielfältige-gesellschaft-gestalten\",\n",
    "    \"https://www.gruene.de/themen/gleichberechtigung-verwirklichen\",\n",
    "    \"https://www.gruene.de/themen/wertegeleitete-außenpolitik\",\n",
    "    \"https://www.gruene.de/themen/demokratie-schuetzen-innere-sicherheit-staerken\",\n",
    "    \"https://www.gruene.de/themen/kultur-foerdern\"\n",
    "]\n",
    "\n",
    "# Variable zum Speichern des gesamten Textes\n",
    "gruene_gesamt = \"\"\n",
    "\n",
    "# Durch die URLs iterieren und den Text extrahieren\n",
    "for url in urls:\n",
    "    try:\n",
    "        # HTTP-Request an die Webseite senden\n",
    "        response = requests.get(url, timeout=10)\n",
    "\n",
    "        # Überprüfen, ob der Request erfolgreich war\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            # Liste für strukturierten Text\n",
    "            structured_text = \"\"\n",
    "\n",
    "            # Alle relevanten Abschnitte mit Headings + zugehörigem Text finden\n",
    "            content_sections = soup.find_all(\"div\", class_=\"rich-text text-lg rich-text max-w-lg\")\n",
    "\n",
    "            for section in content_sections:\n",
    "                # Überschrift aus dem vorherigen <span> mit passender Klasse holen\n",
    "                heading = section.find_previous(\"span\", class_=\"text-xl md:text-2xl group-open:mark-style group-hover:mark-style mark-style-no-hover hover:mark-style\")\n",
    "                \n",
    "                if heading:\n",
    "                    heading_text = heading.get_text(strip=True)\n",
    "                    structured_text += f\"\\n{heading_text}\\n\"\n",
    "\n",
    "                # Alle Absätze aus dem aktuellen Abschnitt hinzufügen\n",
    "                for p in section.find_all(\"p\"):\n",
    "                    paragraph_text = p.get_text(strip=True)\n",
    "                    if paragraph_text:\n",
    "                        structured_text += f\"{paragraph_text}\\n\"\n",
    "\n",
    "            # Wahlprogramm extrahieren (h1, h2, h3, p)\n",
    "            elements = soup.find_all([\"h1\", \"h2\", \"h3\", \"p\"])\n",
    "\n",
    "            for elem in elements:\n",
    "                text = elem.get_text(strip=True)\n",
    "                if not text:\n",
    "                    continue  # Leere Elemente überspringen\n",
    "                \n",
    "                # Formatierung nach Element-Typ\n",
    "                structured_text += f\"{text}\\n\"\n",
    "\n",
    "            # Unnötige Texte entfernen (robustere Methode)\n",
    "            for unwanted in [\"Mehr erfahren ↓\", \"Verwandte Themen\"]:\n",
    "                structured_text = structured_text.replace(unwanted, \"\")\n",
    "\n",
    "            # Wahlprogramm zur Gesamtvariable hinzufügen\n",
    "            gruene_gesamt += structured_text + \"\\n\"\n",
    "\n",
    "            print(f\"Erfolgreich verarbeitet: {url}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Fehler beim Abrufen der Seite {url}: HTTP {response.status_code}\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Fehler beim Abrufen von {url}: {e}\")\n",
    "\n",
    "# Gesamtwortanzahl berechnen\n",
    "word_count = len(gruene_gesamt.split())\n",
    "print(f\"\\nGesamtanzahl der Wörter: {word_count}\")\n",
    "\n",
    "# Wahlprogramm-Text speichern\n",
    "with open(\"gruene.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(gruene_gesamt)\n",
    "\n",
    "print(\"\\nDatei erfolgreich gespeichert als 'gruene.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/klimagerechte-und-soziale-verkehrspolitik\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/die-wirtschaft-stärken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/klima-schützen\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/umwelt-und-natur-schützen\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/energiewende-vorantreiben\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/digitalisierung-vorantreiben\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/ländliche-räume-stärken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/faire-landwirtschaft\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/gesundheit-und-pflege-stärken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/eine-gerechte-gesellschaft\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/einwanderung-gestalten\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/eine-vielfältige-gesellschaft-gestalten\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/gleichberechtigung-verwirklichen\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/wertegeleitete-außenpolitik\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/demokratie-schuetzen-innere-sicherheit-staerken\n",
      "Erfolgreich verarbeitet: https://www.gruene.de/themen/kultur-foerdern\n",
      "\n",
      "Gesamtanzahl der Wörter: 22942\n",
      "\n",
      "Datei erfolgreich gespeichert als 'gruene.txt'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URLs des Wahlprogramms der Grünen\n",
    "urls = [\n",
    "    \"https://www.gruene.de/themen/klimagerechte-und-soziale-verkehrspolitik\",\n",
    "    \"https://www.gruene.de/themen/die-wirtschaft-stärken\",\n",
    "    \"https://www.gruene.de/themen/klima-schützen\",\n",
    "    \"https://www.gruene.de/themen/umwelt-und-natur-schützen\",\n",
    "    \"https://www.gruene.de/themen/energiewende-vorantreiben\",\n",
    "    \"https://www.gruene.de/themen/digitalisierung-vorantreiben\",\n",
    "    \"https://www.gruene.de/themen/ländliche-räume-stärken\",\n",
    "    \"https://www.gruene.de/themen/faire-landwirtschaft\",\n",
    "    \"https://www.gruene.de/themen/gesundheit-und-pflege-stärken\",\n",
    "    \"https://www.gruene.de/themen/eine-gerechte-gesellschaft\",\n",
    "    \"https://www.gruene.de/themen/einwanderung-gestalten\",\n",
    "    \"https://www.gruene.de/themen/eine-vielfältige-gesellschaft-gestalten\",\n",
    "    \"https://www.gruene.de/themen/gleichberechtigung-verwirklichen\",\n",
    "    \"https://www.gruene.de/themen/wertegeleitete-außenpolitik\",\n",
    "    \"https://www.gruene.de/themen/demokratie-schuetzen-innere-sicherheit-staerken\",\n",
    "    \"https://www.gruene.de/themen/kultur-foerdern\"\n",
    "]\n",
    "\n",
    "# Variable zum Speichern des gesamten Textes\n",
    "gruene_gesamt = \"\"\n",
    "\n",
    "# Durch die URLs iterieren und den Text extrahieren\n",
    "for url in urls:\n",
    "    try:\n",
    "        # HTTP-Request an die Webseite senden\n",
    "        response = requests.get(url, timeout=10)\n",
    "\n",
    "        # Überprüfen, ob der Request erfolgreich war\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            # Temporärer String für die aktuelle Seite\n",
    "            structured_text = \"\"\n",
    "\n",
    "            # Alle relevanten Abschnitte finden\n",
    "            content_sections = soup.find_all(\"div\", class_=\"rich-text text-lg rich-text max-w-lg\")\n",
    "\n",
    "            for section in content_sections:\n",
    "                # Überschrift aus vorherigem <span> mit passender Klasse holen\n",
    "                heading = section.find_previous(\"span\", class_=\"text-xl md:text-2xl group-open:mark-style group-hover:mark-style mark-style-no-hover hover:mark-style\")\n",
    "                \n",
    "                if heading:\n",
    "                    heading_text = heading.get_text(strip=True)\n",
    "                    structured_text += f\"## {heading_text}\\n\"\n",
    "\n",
    "                # Alle Absätze aus dem Abschnitt hinzufügen\n",
    "                for paragraph in section.find_all(\"p\"):\n",
    "                    paragraph_text = paragraph.get_text(strip=True)\n",
    "                    structured_text += f\"# {paragraph_text}\\n\"\n",
    "\n",
    "            # Weitere relevante Texte extrahieren (h1, h2, h3, p)\n",
    "            elements = soup.find_all([\"h1\", \"h2\", \"h3\", \"p\"])\n",
    "\n",
    "            for elem in elements:\n",
    "                text = elem.get_text(strip=True)\n",
    "                if not text:\n",
    "                    continue  # Leere Elemente überspringen\n",
    "                \n",
    "                # Formatierung nach Element-Typ\n",
    "                if elem.name == \"h1\":\n",
    "                    structured_text += f\"## {text}\\n\"\n",
    "                elif elem.name in [\"h2\", \"h3\"]:\n",
    "                    structured_text += f\"### {text}\\n\"\n",
    "                elif elem.name == \"p\":\n",
    "                    structured_text += f\"# {text}\\n\"\n",
    "\n",
    "            # Unnötige Texte entfernen\n",
    "            for unwanted in [\"Mehr erfahren ↓\", \"Verwandte Themen\"]:\n",
    "                structured_text = structured_text.replace(unwanted, \"\")\n",
    "\n",
    "            # Wahlprogramm zur Gesamtvariable hinzufügen\n",
    "            gruene_gesamt += structured_text + \"\\n\"\n",
    "\n",
    "            print(f\"Erfolgreich verarbeitet: {url}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Fehler beim Abrufen der Seite {url}: HTTP {response.status_code}\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Fehler beim Abrufen von {url}: {e}\")\n",
    "\n",
    "# Gesamtwortanzahl berechnen\n",
    "word_count = len(gruene_gesamt.split())\n",
    "print(f\"\\nGesamtanzahl der Wörter: {word_count}\")\n",
    "\n",
    "# Wahlprogramm-Text speichern\n",
    "with open(\"gruene.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(gruene_gesamt)\n",
    "\n",
    "print(\"\\nDatei erfolgreich gespeichert als 'gruene.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = urls[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "text_all = ''\n",
    "\n",
    "for url in urls:\n",
    "     response  = requests.get(url)\n",
    "     if response.status_code == 200:\n",
    "          page = response.text\n",
    "     else:\n",
    "         print(f\"Seite konnte nicht abgerufen werden - Status Code {response.status_code}\")\n",
    "     \n",
    "     soup = BeautifulSoup(page, 'html.parser')\n",
    "     \n",
    "     \n",
    "     heading_tag = soup.find(class_ = \"flex w-full flex-col\")\n",
    "     heading_text_list = heading_tag.find_all(['h1', 'p'])\n",
    "     \n",
    "     body_tag = soup.find(class_ = \"flex flex-col gap-20 md:gap-24\")\n",
    "     body_text_list = body_tag.find_all(['span', 'h2', 'p'])\n",
    "     text_list = heading_text_list + body_text_list\n",
    "     \n",
    "     text = ''\n",
    "     \n",
    "     for text_element in text_list:\n",
    "         if text_element.name == 'h1':\n",
    "              text +='### ' + text_element.text + '\\n'\n",
    "         elif text_element.name in ('h2', 'span'):\n",
    "              text += '## ' + text_element.text + '\\n'\n",
    "         else:\n",
    "              text += '# ' + text_element.text + '\\n'\n",
    "     \n",
    "     text_all += text.strip()\n",
    "\n",
    "file_name = 'gruene.txt'\n",
    "\n",
    "if os.path.exists(file_name) == False:\n",
    "        with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
